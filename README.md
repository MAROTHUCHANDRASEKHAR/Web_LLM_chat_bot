# Web_LLM_chat_bot
WebLLMChat is a web-based chat interface powered by WebLLM, which allows large language models (LLMs) like LLaMA or Mistral to run directly in the browser using WebGPU, without needing a server backend. This means users can interact with AI models privately, with all computation done locally on their device.
